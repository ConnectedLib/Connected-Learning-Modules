---
layout: module
title: 3.5 Evaluation Plans
module_name: assessment
module_full_name: Assessment and Evaluation
section: 3. Evaluation
subsection: three-five
---

An evaluation plan is a roadmap for the activities and assessments you will conduct to answer your questions. If your evaluation plan will be used only internally, you may not need every section. If you are working with a partner, make sure you are both onboard with the plan. 

#### Overview and Background Information  

If you will be sharing it with people who aren’t deeply familiar with the project, introduce the project and the reason for the evaluation. After reading these sections, your readers should have a general sense of what is being evaluated and why.  

- **Executive summary**. An abstract of the entire report. This may be the only section that some of your stakeholders read, so capture the “gist” of the evaluation clearly and succinctly. You can also write different summaries for different stakeholders.  
- **Project (or program, initiative, etc.) description**. Include a high-level overview, then go into detail about the elements or activities that make it up. Include any history or context that might be helpful.   
- **Purpose of the evaluation**. Describe the general reason you are conducting an evaluation and what you hope to get out of it. A detailed examination of your evaluation questions comes later, so don’t get too granular here.  
- **Key stakeholders**. Introduce your readers to the key people involved with or affected by your project (see Section X). You can also introduce key project staff here.  

#### Program Outcomes 

These sections explain in greater detail what your program does, and how and why you expect it to achieve what you want.  

- **Program goals**. Introduce the impacts and outcomes you hope your project will have.  
- **Theory of change or logic model**. This section explains “how and why the program will work”<sup>[16](#fn16)</sup> in both narrative and graphic formats. (For more about developing theories of change, see the Connected Learning Programs module.) 
- **Activities**. Include a list of all the activities that will take place as part of the project being evaluated. You may break them into categories—e.g., activities that staff will complete, activities the partner will complete, and activities the program participants will complete. 

#### About the Evaluation  

Explain exactly what you are evaluating, why, and how.  

- **Elements to be evaluated**. Broadly define the scope of the evaluation—what will be evaluated and what will not be. You may wish to break a large list of activities into sections—front-end, formative, and summative. It is important to make sure your most important stakeholders are completely on board with this part of the plan—especially the things you will leave out—so that there is no confusion or disappointment later.  
- **Evaluation questions**. Lay out the precise evaluation questions you developed earlier in this module. They should flow naturally from what you discussed in the previous section of the evaluation plan.  
- **Indicators**. Describe the indicators you will be looking at, and explain how they relate to your outcomes.  
- **Data sources for evaluation**. Finally, describe the data sources you will draw from and how they relate to your indicators.  

#### Methodology 

This is the “nitty gritty” section that lays out the details of how you will collect your data.  

- **Data collection strategy**. Describe how your data will be collected, by whom, and from whom. If there was any uncertainty or dispute about data collection in your planning process, explain why you made the choices you did. Will you be conducting formative assessments throughout the course of the project? Include that information here.  
- **Evaluation tools to use**. Describe any instruments or resources you will use for data collection. If you have created custom instruments (interview protocols, etc.), you can describe them here, and include them as appendices to the evaluation plan. 
- **Reporting strategy**. How will you communicate the results to your stakeholders? Will you use different strategies for different audiences? What elements will be included for each group? For instance, youth participants probably don’t care whether your partnership project was within budget, but they might like to know how many of their peers participated. This information could be disseminated through a display in your library, a newsletter, or on the library’s social media accounts.
<br>
<br>

<a name="fn4">4</a>:  --https://www.youtube.com/watch?v=WXbkeFIEN8Y&feature=youtu.be 5:15 
<br> 
<a name="fn5">5</a>:  -- Surrounded by Science: Learning Science in Informal Environments. (2010). Washington, D.C.: National Academies Press. https://doi.org/10.17226/12614 p 111
<br> 
<a name="fn6">6</a>:  -- Bonney, R., Ellenbogen, K., Goodyear, L., & Hellenga, R. (Eds.). (2001). Principal investigator’s guide: Managing evaluation in informal STEM education projects. Washington, D.C.: Center for Advancement of Informal Science Education. Retrieved from http://www.informalscience.org/evaluation/pi-guide (p3)
<br> 
<a name="fn7">7</a>:  -- Bonney, R., Ellenbogen, K., Goodyear, L., & Hellenga, R. (Eds.). (2001). Principal investigator’s guide: Managing evaluation in informal STEM education projects. Washington, D.C.: Center for Advancement of Informal Science Education. Retrieved from http://www.informalscience.org/evaluation/pi-guide (p4)
<br> 
<a name="fn8">8</a>:  -- https://youtu.be/WXbkeFIEN8Y 28:40
<br> 
<a name="fn9">9</a>:  -- http://search.credoreference.com/content/entry/sageeval/evaluation_use/
<br> 
<a name="fn10">10</a>:  --Bonney, R., Ellenbogen, K., Goodyear, L., & Hellenga, R. (Eds.). (2001). Principal investigator’s guide: Managing evaluation in informal STEM education projects. Washington, D.C.: Center for Advancement of Informal Science Education. Retrieved from http://www.informalscience.org/evaluation/pi-guide (p13)
<br> 
<a name="fn11">11</a>:  -- PI Guide pg. 51
<br> 
<a name="fn12">12</a>:  -- Bonney, R., Ellenbogen, K., Goodyear, L., & Hellenga, R. (Eds.). (2001). Principal investigator’s guide: Managing evaluation in informal STEM education projects. Washington, D.C.: Center for Advancement of Informal Science Education. Retrieved from http://www.informalscience.org/evaluation/pi-guide (p16).
<br> 
<a name="fn13">13</a>:  -- Westat, J. F. (2010). The 2010 user-friendly handbook for project evaluation. Washington, D.C.: National Science Foundation. Retrieved from http://www.informalscience.org/sites/default/files/TheUserFriendlyGuide.pdf pp8-9
<br> 
<a name="fn14">14</a>:  -- PI guide p 51
<br> 
<a name="fn15">15</a>:  -- Kellogg p33
<br>
<a name="fn16">16</a>:  -- Weiss, C. H. (1995). Nothing as practical as good theory: Exploring theory-based evaluation for comprehensive community initiatives for children and families. New Approaches to Evaluating Community Initiatives: Concepts, Methods, and Contexts, 1, 65–92.
