---
layout: module
title: 2.0 Assessment
module_name: assessment
module_full_name: Assessment and Evaluation
section: 2. Assessment
subsection: two-zero
---

In this introduction, you will learn what mentoring is and how it can support connected learning in the library.

## Learning Outcomes For This Section

**After completing Section 1: Introduction, you will be able to...**
<ul class="fancy">
  <li>Determine an assessment question</li>
  <li>Decide what to measure that will answer your question</li>
  <li>Choose and implement a data collection method</li>
  <li>Analyze the data you collect </li>
  <li>Use the data to construct evidence that will help you answer your assessment question </li>
</ul>

We've had a wall where customers can put up Post-It notes on certain topics, like, ‘What was your favorite book? What do you love about the library?’ So it's kind of like an informal kind of subjective opinion gathering rather than a formal assessment. -- INTS_031 

 

An assessment is a way to answer a single question at one point in time. Assessment can be a quick and easy process if you have a simple question, or it can be more extensive if you need to assess something large or complicated. Multiple assessments can be conducted to answer questions that involve comparisons, such as before-and-after questions, or to provide multiple perspectives. Assessments focus on the state or extent of something, such as what or how much individuals are learning, without digging deeper into value-based judgments like are participants learning enough? or how can we make this partnership more productive?<sup>[3](#fn3)</sup> 

**ASSESSMENT QUESTION EXAMPLES** 

*What did participants learn from the robotics program?*  

*How much are participants collaborating?* 

*How are teens helping each other while completing their projects?* 

### Choosing what to measure 

When you know the question that needs to be answered, the next step is to decide how to answer it. The factor that you will measure in order to help answer the question is called an indicator. For instance, you may want to know if participating in a program helps participants become more confident in the use of photo editing software. What you want to know is the level of participants’ confidence in using the software, but that isn’t directly measurable in the way the number of attendees is. You may decide to measure participants’ self-reported increase in confidence (by using a feedback survey, perhaps) or demonstrations of confident behavior that you observe. Using assessments for both measures will provide a more complete picture of the situation.  

**INDICATOR EXAMPLES** 

*Participants’ performance on a number of questions at the end of the program*

*The number of times participants form collaborative groups in a lab session* 

*Teen’s behaviors and conversations when collaborating* 

### Collecting data 

You need to collect data on your measure (or measures) in order to answer your question. Data collection can be resource-intensive, so choose your data sources and collection strategy wisely. Ask the following questions (adapted from page 53 of the <a href="https://projectoutcome.org/surveys-resources/informed-consent-guidelines" target="_blank">Principal Investigator’s Guide</a>) to guide you through the process:  

1. **What kind of information do you need?** Do you need to know about opinions or attitudes? Knowledge levels? Details about implementation?  
2. **What is the best method to obtain that information?** You have many choices for data collection—surveys, focus groups, interviews, and more.  
3. **What is the best strategy for collecting that information via that method for this project?** From whom do you need to collect information? Where is the best place to reach them via the method(s) you’ve chosen? When should this happen? If there is a facilitator, whom should that be?  

**DATA COLLECTION EXAMPLES** 

*How many questions participants get right in a Jeopardy! game at the end of the program* 

*A staff member uses an observation form to record the number of times participants form collaborative groups* 

*A staff member writes field notes based on the interactions they observe* 

#### Quantitative or qualitative 

To put it simply, quantitative data means numbers, and qualitative data means anything else—usually text or spoken words, but could also include things like images, sounds, or behaviors. Traditional library assessments tend to be quantitative in nature, like the number of items borrowed or the number of program participants. Collecting qualitative data by listening to or observing people can better capture individual experiences, thoughts, and attitudes. Your assessment may include both—a survey can have both quantitative and qualitative questions, and an observation protocol may involve both counting the number of times something happens and listening to someone’s comments. You can also quantitatively analyze qualitative data (see the section on analyzing data below).  

#### Data collection instruments 

An instrument is a tool you use in the collection process—for example, a survey, interview guide, or observation record. You can find examples of instruments for informal learning in the Additional Resources for this section. However, connected learning programs are often unique, with one-of-a-kind elements that may need one-of-a-kind assessments. You may wish to modify someone else’s instrument to fit your own assessment needs, or even create one that is entirely original.  

#### Testing the process 

Before diving headlong into data collection, test the entire process. For a small and simple assessment, this could simply be asking a co-worker to review your plan. A larger effort should be tested more thoroughly, ideally with a sample that resembles who or what you will be assessing. A large survey, for example, would benefit from being tested with a handful of teens first. As you conduct your tests, consider the following questions:  

- Does the instrument you are using give you the kind of data you need to answer your question? Do you need to make changes to wording, format, time or place?  
- Are there ways you can automate or simplify data collection? For instance, you could provide computers at the library for people to fill out a survey online, rather than handing them a sheet of paper to fill out . 
- Do you have the capacity to handle the data collection you’re planning? If an interview takes much longer than expected, for example, you may need to either shorten your interview instrument, add more staff to the effort, or increase the amount of time your assessment will run.  
- Do you need to collect any baseline data so you can make before and after comparisons? 
- Is there a way that data collection can happen seamlessly (for instance, the teens provide you with the data you need as part of the program), and not intrusive (such as taking time from the program to have the teens fill out a feedback form)? 

**PRIVACY AND CONSENT** 

Be sure to respect your participants’ privacy and autonomy as you are collecting data (and any time outside stakeholders are involved). This is particularly important when you are interacting with minors. <a href="https://projectoutcome.org/" target="_blank">Project Outcome</a> is a good starting place for learning about <a href="https://projectoutcome.org/surveys-resources/informed-consent-guidelines" target="_blank">issues of privacy and consent in library assessment</a> (requires free registration). 

 

#### Ways to collect data 

The following table includes some—though certainly not all!—methods to collect data for your assessment. Each method has potential strengths and weaknesses and can be used to assess a wide variety of factors. Choose one (or more) that fits your question, your program, and your capacity.  
